---
layout: post
title: Better randomized algorithms for k-server
use_math: true
comments: true
---

This blog post discusses the [2017 paper](https://arxiv.org/abs/1711.01085) by Bubeck et al on $$k$$-server using multiscale entropic regularization.

## The Problem
$$k$$-server is a prototype problem to study in online algorithms. Given a metric space $$(X,d)$$, and requests (that correspond to points in the metric space) that arrive in an online fashion, the goal is to maintain a configuration of $$k$$ servers at points in $$X$$ such that:

1. a server is moved to the request point at the end of every iteration, and
2. the sum over all iterations of Earthmover distances between consecutive configurations of servers is minimized. This is the total cost of "realizing" the algorithm

Observe that the paging problem is a special instance of the $$k$$-server problem when the metric space is the uniform metric.

## Some prior results

The $$k$$-server problem was introduced in Manasse et al, and the authors conjectured a deterministic $$k$$-competitive algorithm for all metric spaces. This bound must be essentially tight for deterministic algorithms because the closely related "paging problem" has a deterministic lower bound of $$k$$. This lower bound is simple to see because an adverserial request sequence can maintain a set of $$k+1$$ pages that are requested in a round-robin fashion such that the request at every iteration is the page not present in the cache of the deterministic algorithm. The optimal solution would only have a page fault once every $$k$$ iterations if it swapped out the correct page.

### Best known deterministic algorithm for $$k$$-server
In general metric spaces, the best known result is due to Koutsoupias and Papadimitriou who presented a $$2k-1$$ competitive algorithm which they call as the "work function" algorithm. Given some initial configuration $$A_0$$ and a set of queries $$\rho$$ the work function $$w_{\rho} (C)$$ for some configuration $$C$$ is the cost associated with optimal set of moves starting from $$A_0$$ that end at $$C$$ such that the requests made at every iteration are respected. The work function for all configurations for some set of requests $$\rho = \{ r_1,\dots, r_n \}$$ can be computed using dynamic programming as:
\begin{equation}
	w_{\{r_1,\dots,r_n\}}} (C) = \min_{x \in C} \{ w_{\{r_1,\dots,r_{n-1}\}} (C \setminus x \cup \{r_n\}) + d(x,r_n)\}
\end{equation}
If at iteration $$n-1$$, the server configuration is $$S$$, in iteration $$n$$, the work function algorithm picks the configuration $$S'$$ that minimizes $$w_{\{r_1,\dots,r_n\}} (S') + D (S,S')$$ where $$D$$ is the Earthmover distance in the metric $$d$$. Intuitively, this decision takes into equal weightage the historical goodness of the configuration $$S'$$ (the first term) and the cost of moving the servers to $$S'$$ (the second term). This update rule can be computed in polynomial time because one need not check all possible configurations, it is sufficient to check those that move exactly one server to the request point.



The competitive ratio of this algorithm relies on the fact that 

