---
layout: post
title: Online Convex Programming
use_math: true
---

This blog post discusses Martin Zinkevich's 2003 paper Online Convex Programming and Generalized Infinitesimal Gradient Ascent.

The Online Convex Programming framework introduced in Zinkevich's [2003 paper](https://people.eecs.berkeley.edu/~brecht/cs294docs/week1/03.Zinkevich.pdf) models a wide range of "decision-under-uncertainty" optimization problems. As the name suggests, OCP is a natural online extension of convex optimization. At each time $$t = 1,2,\dots,T$$ an agent must pick a value $$x_t$$ from a given (time-invariant) convex domain $$D$$. Once the agent makes a choice, the environment reveals a convex function $$g_t$$ and the agent incurs a cost of $$g_t (x_t)$$. The goal of the agent is to minimize the total cost incurred. The _regret_ $$R$$ associated with a set of choices $$\mathbf{x} = \{ x_t \}$$ made by the agent is measured against the value of the optimal static decision as
\begin{equation}
	R(\mathbf{x}) = \sum_t g_t (x_t) - \min_{x^\* \in D} \sum_{t} g_t (x^\*)
\end{equation}
There are some important things to discuss about this problem:
1. Even if $$D = [0,1]^d$$ and $$g_t : D \to [0,1]$$, it is apparent that no deterministic Turing machine can solve the problem with a regret bound of $$\Omega(T)$$ when the regret is defined as
\begin{equation}
	R(\mathbf{x}) = \sum_t g_t (x_t) - \sum_t \min_{x \in D} g_t (x)
\end{equation}
This can be argued by the simple adverserial choice of
\begin{equation}
	g_t (x) = \begin{cases}
		\| x \|_\infty \quad  & \| x_t \|_\infty \ge 0.5 \\
		1 - \| x \|_\infty  & \| x_t \|_\infty \le 0.5 
	\end{cases}
\end{equation}
where $$x_t$$ is the choice made by the agent at time $$t$$ and $$\| \cdot \|_\infty$$ is $$\ell_\infty$$-norm. At every time, the agent incurs a cost of at least $$0.5$$ while the minimum of $$g_t$$ is always $$0$$.
2. The optimal static decision is a natural notion to define the regret against in many classes of problems. An example is that of finding the value of the optimal solution to an online constrained minimization problem. [Strong Lagrangian duality][1] allows the constrained minimization (primal) problem to be converted into an equivalent concave unconstrained maximization (dual) problem. The catch is that the optimal dual solution $$\lambda^\*$$ cannot usually be computed causally. However this framework asks a crucial question - can we design a primal-dual algorithm that "learns" $$\lambda^\*$$ which is the solution to $$\max_{\lambda \ge 0} \mathcal{L}(\lambda)$$ (where $$\mathcal{L}$$ is the Fenchel dual function)

Being able to estimate the optimal Lagrange multiplier would make life much easier because the dual problem inherently has the power of concavity. this comes with a catch of its own, since in most such problems the optimal multiplier cannot be computable causally and hence

[1] : https://en.wikipedia.org/wiki/Duality_\(optimization\)#The_strong_Lagrangian_principle:_Lagrange_duality